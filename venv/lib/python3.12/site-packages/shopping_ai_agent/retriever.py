import os, requests
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document

def build_chroma_from_api(api_url, persist_path, embed_model="mxbai-embed-large"):
    if not os.path.exists(persist_path):
        os.makedirs(persist_path)

    response = requests.get(api_url)
    products = response.json().get("products", [])

    embeddings = OllamaEmbeddings(model=embed_model)

    vector_store = Chroma(
        collection_name="shopping_products",
        persist_directory=persist_path,
        embedding_function=embeddings
    )

    if len(vector_store.get()["ids"]) == 0:
        documents = []
        for product in products:
            content = (
                f"Product Title: {product.get('title', 'N/A')}\n"
                f"Product Price: ${product.get('price', 'N/A')}\n"
                f"Product Model: {product.get('model', 'N/A')}\n"
                f"Product Category: {product.get('category', 'N/A')}\n"
                f"Product Description: {product.get('description', 'N/A')}\n"
            )
            documents.append(Document(
                page_content=content,
                metadata={
                    "category": product.get("category", "unknown"),
                    "price": product.get("price", 0.0)
                },
                id=str(product.get("id", f"unknown-{len(documents)}")),
            ))

        vector_store.add_documents(documents)


    return vector_store.as_retriever(search_kwargs={"k": 5})
